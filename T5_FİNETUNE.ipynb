{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzdDDNcVFOAllcb3Mz9WQ9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "id": "ECtlVVrfU5Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "S5vxv0eKVhU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_API_KEY\"] = \"abda9f461371669c2516207660e00058a83e1e09\"\n",
        "os.environ[\"WANDB_PROJECT\"] = \"flowchart-t5\"\n"
      ],
      "metadata": {
        "id": "vDiWq34dC5lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score\n"
      ],
      "metadata": {
        "id": "AKwLxDUZERrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "8Obc5QqpLE7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "0HlNoN4rR4oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
        "import os, json, torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "import evaluate\n",
        "\n",
        "# 1. JSONL dosyasını oku\n",
        "all_data_file = '/content/drive/MyDrive/formatted_akış.jsonl'\n",
        "with open(all_data_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    full_data = [json.loads(line) for line in f]\n",
        "\n",
        "# 2. Train-test ayrımı\n",
        "train_data, test_data = train_test_split(full_data, test_size=0.1, random_state=42)\n",
        "dataset = DatasetDict({\n",
        "    \"train\": Dataset.from_list(train_data),\n",
        "    \"test\": Dataset.from_list(test_data)\n",
        "})\n",
        "\n",
        "# 3. Model ve tokenizer\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# 4. Preprocessing\n",
        "def preprocess_function(examples):\n",
        "    model_inputs = tokenizer(examples[\"input\"], max_length=1024, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(examples[\"output\"], max_length=1024, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# 5. Eğitim ayarları\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./t5_flowchart_output\",\n",
        "    eval_strategy=\"no\",  # Değerlendirme yapılmasın\n",
        "    num_train_epochs=35,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    save_total_limit=3,\n",
        "    fp16=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "# 6. Trainer (metrics hesaplamadan)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# 7. Eğitimi başlat\n",
        "trainer.train()\n",
        "\n",
        "# 8. Eğitim sonrası elle metrik hesaplama\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# İlk 50 test örneğinde değerlendirme\n",
        "decoded_preds = []\n",
        "decoded_labels = []\n",
        "\n",
        "for i in range(min(50, len(dataset[\"test\"]))):\n",
        "    input_text = dataset[\"test\"][i][\"input\"]\n",
        "    target_text = dataset[\"test\"][i][\"output\"]\n",
        "\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(input_ids, max_length=1024)\n",
        "\n",
        "    pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds.append(pred_text)\n",
        "    decoded_labels.append(target_text)\n",
        "\n",
        "    del input_ids, outputs\n",
        "    torch.cuda.empty_cache()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ved5rgWMb5fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install rouge_score\n",
        "!pip install evaluate\n",
        "!pip install bert_score\n",
        "!pip install transformers datasets accelerate"
      ],
      "metadata": {
        "id": "3SUAn4cXAE9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate # 'evaluate' kütüphanesi yüklü değilse: pip install evaluate\n",
        "\n",
        "# Metrikleri bir kez yükleyin\n",
        "# Eğer bu kütüphaneler yüklü değilse:\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "bertscore = evaluate.load(\"bertscore\")"
      ],
      "metadata": {
        "id": "5z2-2VAfANIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_all_metrics(decoded_preds, decoded_labels, lang='en'):\n",
        "    rouge_result = rouge.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels,\n",
        "        use_stemmer=True\n",
        "    )\n",
        "\n",
        "    bertscore_result = bertscore.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels,\n",
        "        lang=lang\n",
        "    )\n",
        "\n",
        "    exact_matches = [int(pred.strip() == label.strip()) for pred, label in zip(decoded_preds, decoded_labels)]\n",
        "    exact_match_score = np.mean(exact_matches)\n",
        "\n",
        "    print(\"\\n--- DEĞERLENDİRME METRİKLERİ ---\")\n",
        "    print(f\"ROUGE-1:    {rouge_result['rouge1']:.4f}\")\n",
        "    print(f\"ROUGE-2:    {rouge_result['rouge2']:.4f}\")\n",
        "    print(f\"ROUGE-L:    {rouge_result['rougeL']:.4f}\")\n",
        "    print(f\"ROUGE-Lsum: {rouge_result['rougeLsum']:.4f}\")\n",
        "\n",
        "    print(f\"BERTScore (F1): {np.mean(bertscore_result['f1']):.4f}\")\n",
        "    print(f\"Exact Match:    {exact_match_score:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"rouge1\": rouge_result[\"rouge1\"],\n",
        "        \"rouge2\": rouge_result[\"rouge2\"],\n",
        "        \"rougeL\": rouge_result[\"rougeL\"],\n",
        "        \"rougeLsum\": rouge_result[\"rougeLsum\"],\n",
        "        \"bertscore_f1\": np.mean(bertscore_result[\"f1\"]),\n",
        "        \"exact_match\": exact_match_score\n",
        "    }\n",
        "results = evaluate_all_metrics(decoded_preds, decoded_labels, lang='tr')\n",
        "print(\"\\nDeğerlendirme Sonuçları:\", results)\n"
      ],
      "metadata": {
        "id": "euxHYHhWoZnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Tek test örneği yazdır\n",
        "print(\"\\n--- Örnek Tahmin ---\")\n",
        "print(\"Giriş:\\n\", dataset[\"test\"][5][\"input\"])\n",
        "print(\"\\nModel Çıktısı:\\n\", decoded_preds[5])\n",
        "print(\"\\nGerçek Çıktı:\\n\", decoded_labels[5])"
      ],
      "metadata": {
        "id": "zBCN-SoosmdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "input_lengths = [len(tokenizer(example[\"input\"]).input_ids) for example in full_data]\n",
        "output_lengths = [len(tokenizer(example[\"output\"]).input_ids) for example in full_data]\n",
        "\n",
        "print(f\"Input max: {max(input_lengths)}, mean: {sum(input_lengths)//len(input_lengths)}\")\n",
        "print(f\"Output max: {max(output_lengths)}, mean: {sum(output_lengths)//len(output_lengths)}\")\n",
        "\n",
        "plt.hist(input_lengths, bins=50, alpha=0.5, label='input')\n",
        "plt.hist(output_lengths, bins=50, alpha=0.5, label='output')\n",
        "plt.legend()\n",
        "plt.title(\"Token Uzunluk Dağılımı\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "76s1kslzF7IP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}