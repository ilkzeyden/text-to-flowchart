{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73Z2QID8Btvd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fBPpw1VQBvOF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Adım: Verileri Yükleme\n",
        "# -----------------------------\n",
        "train_file = r'/content/drive/My Drive/akış-diyagramı-örnekleri-verileri.xlsx'  # Eğitim veri dosyası\n",
        "valid_file = r'/content/drive/My Drive/akışlar-test-verileri.xlsx'  # Test veri dosyası\n",
        "\n",
        "df_train = pd.read_excel(train_file)\n",
        "df_valid = pd.read_excel(valid_file)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. BERT ile Adım Türü Tahmini\n",
        "# -----------------------------\n",
        "\n",
        "# Dataset sınıfı\n",
        "class BertDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# BERT Modeli ve Tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\", token='<your_actual_token>')\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\"dbmdz/bert-base-turkish-cased\", num_labels=8, token='<your_actual_token>')\n",
        "\n",
        "# Eğitim verileri hazırlama\n",
        "bert_train_X = [f\"Adım No: {row['Adım No']}, Adım Açıklaması: {row['Adım Açıklaması']}\" for _, row in df_train.iterrows()]\n",
        "bert_train_y = df_train['Adım Türü Label'].values\n",
        "bert_valid_X = [f\"Adım No: {row['Adım No']}, Adım Açıklaması: {row['Adım Açıklaması']}\" for _, row in df_valid.iterrows()]\n",
        "bert_valid_y = df_valid['Adım Türü Label'].values\n",
        "\n",
        "train_dataset = BertDataset(bert_train_X, bert_train_y, bert_tokenizer)\n",
        "valid_dataset = BertDataset(bert_valid_X, bert_valid_y, bert_tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Eğitim döngüsü\n",
        "optimizer = torch.optim.AdamW(bert_model.parameters(), lr=5e-5)\n",
        "bert_model.train()\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(8):  #----------------------------------------------------------------------------------------- 3 Epoch\n",
        "    epoch_train_loss = 0\n",
        "    bert_model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = bert_model(\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            labels=batch['labels']\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss.item()\n",
        "    train_losses.append(epoch_train_loss / len(train_loader))\n",
        "\n",
        "    # Doğrulama sırasında loss hesaplama\n",
        "    epoch_valid_loss = 0\n",
        "    bert_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_loader:\n",
        "            outputs = bert_model(\n",
        "                input_ids=batch['input_ids'],\n",
        "                attention_mask=batch['attention_mask'],\n",
        "                labels=batch['labels']\n",
        "            )\n",
        "            loss = outputs.loss\n",
        "            epoch_valid_loss += loss.item()\n",
        "    valid_losses.append(epoch_valid_loss / len(valid_loader))\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} | Train Loss: {train_losses[-1]:.4f} | Validation Loss: {valid_losses[-1]:.4f}\")\n",
        "\n",
        "# BERT Doğrulama Performansı\n",
        "bert_predictions = []\n",
        "bert_model.eval()\n",
        "with torch.no_grad():\n",
        "    for text in bert_valid_X:\n",
        "        encoding = bert_tokenizer(\n",
        "            text,\n",
        "            max_length=128,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        output = bert_model(\n",
        "            input_ids=encoding['input_ids'],\n",
        "            attention_mask=encoding['attention_mask']\n",
        "        )\n",
        "        preds = torch.argmax(output.logits, dim=1).item()\n",
        "        bert_predictions.append(preds)\n",
        "\n",
        "# Performans Metrikleri\n",
        "print(\"BERT Model Accuracy:\", accuracy_score(bert_valid_y, bert_predictions))\n",
        "print(\"BERT Classification Report:\")\n",
        "print(classification_report(bert_valid_y, bert_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Snr6VkWzBvLb"
      },
      "outputs": [],
      "source": [
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5wHjoqrBvBl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Adım: Veriyi Hazırlama\n",
        "# -----------------------------\n",
        "# Adım açıklamaları ve koşul etiketini çıkarıyoruz\n",
        "df_train['Adım Açıklaması'] = df_train['Adım Açıklaması'].astype(str)\n",
        "df_valid['Adım Açıklaması'] = df_valid['Adım Açıklaması'].astype(str)\n",
        "\n",
        "# Koşul türü ile ilişkili olan adım sıralarını tahmin etmeyi amaçlıyoruz\n",
        "# Koşul (evet/hayır) verisini kullanacağız (Koşul Label)\n",
        "\n",
        "# Adım türüne göre koşul (adım türü koşul olanlar)\n",
        "df_train_condition = df_train[df_train['Adım Türü'] == 'Koşul']\n",
        "df_valid_condition = df_valid[df_valid['Adım Türü'] == 'Koşul']\n",
        "\n",
        "# Adım türüne göre sırasıyla adımları tahmin edeceğiz (LSTM kullanarak)\n",
        "# Adım sırasını ve koşul sonrasındaki adımları tahmin etme\n",
        "\n",
        "# -----------------------------\n",
        "# 3. LSTM Modeli İçin Veri Hazırlığı\n",
        "# -----------------------------\n",
        "# Adım açıklamalarını sayısal verilere dönüştürmek için tokenizer kullanıyoruz\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df_train['Adım Açıklaması'])\n",
        "X_train = tokenizer.texts_to_sequences(df_train['Adım Açıklaması'])\n",
        "X_valid = tokenizer.texts_to_sequences(df_valid['Adım Açıklaması'])\n",
        "\n",
        "# Veriyi sabit uzunlukta tutmak için pad_sequence kullanıyoruz\n",
        "max_sequence_length = 100  # Bu değeri verinin uzunluğuna göre ayarlayabilirsiniz\n",
        "X_train = pad_sequences(X_train, maxlen=max_sequence_length)\n",
        "X_valid = pad_sequences(X_valid, maxlen=max_sequence_length)\n",
        "\n",
        "# Koşul etiketlerini alıyoruz (Koşul => Evet ve Hayır durumu)\n",
        "y_train_condition = df_train_condition['Adım Türü Label'].values\n",
        "y_valid_condition = df_valid_condition['Adım Türü Label'].values\n",
        "\n",
        "# Adım sıralarını alıyoruz (Koşul dışındaki her adım sırası)\n",
        "y_train_step = df_train['Adım No'].values\n",
        "y_valid_step = df_valid['Adım No'].values\n",
        "\n",
        "# -----------------------------\n",
        "# 4. LSTM Modeli: Adım Sırası ve Koşul Durumu\n",
        "# -----------------------------\n",
        "# LSTM Modeli (Adım Sırası ve Koşul Durumu için)\n",
        "lstm_model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_sequence_length),\n",
        "    LSTM(128, return_sequences=False),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='linear')  # Bu çıkış, adım sırasını tahmin etmek için\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "# Adım sırasını tahmin etme (sürekli değişken olduğu için 'linear' aktivasyon)\n",
        "lstm_model.fit(X_train, y_train_step, epochs=1809, batch_size=512, validation_data=(X_valid, y_valid_step)) #----------------------epoch\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Koşul Durumu için LSTM Modeli\n",
        "# -----------------------------\n",
        "# Koşul adımlarında (Evet/Hayır) tahmin yapmak için farklı bir model\n",
        "condition_model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_sequence_length),\n",
        "    LSTM(128, return_sequences=False),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Koşul doğru/yanlış tahmin etmek için\n",
        "])\n",
        "\n",
        "condition_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Koşul etiketini tahmin etme (evet/hayır)\n",
        "# Filter X_train to include only the rows corresponding to 'Koşul' steps\n",
        "X_train_condition = X_train[df_train['Adım Türü'] == 'Koşul']\n",
        "X_valid_condition = X_valid[df_valid['Adım Türü'] == 'Koşul']\n",
        "\n",
        "# Now fit the model with the filtered data\n",
        "condition_model.fit(\n",
        "    X_train_condition,\n",
        "    y_train_condition,\n",
        "    epochs=235,                       #---------------------------------------------------------------------------------epoch\n",
        "    batch_size=16,\n",
        "    validation_data=(X_valid_condition, y_valid_condition)\n",
        ")\n",
        "# -----------------------------\n",
        "# 6. Sonuçları Değerlendirme\n",
        "# -----------------------------\n",
        "# Adım sırasını tahmin etme (Adım No) için\n",
        "step_predictions = lstm_model.predict(X_valid)\n",
        "step_predictions = np.round(step_predictions)\n",
        "\n",
        "# Koşul durumunu tahmin etme (Koşul Label) için\n",
        "condition_predictions = condition_model.predict(X_valid)\n",
        "condition_predictions = (condition_predictions > 0.5).astype(int)\n",
        "\n",
        "condition_predictions = condition_model.predict(X_valid_condition)\n",
        "condition_predictions = (condition_predictions > 0.5).astype(int)\n",
        "\n",
        "# Adım sırası ve koşul durumunun doğruluğunu değerlendirme\n",
        "print(\"Adım Sırası Doğruluk Skoru:\", accuracy_score(y_valid_step, step_predictions))\n",
        "print(\"Koşul Durumu Doğruluk Skoru:\", accuracy_score(y_valid_condition, condition_predictions))\n",
        "print(\"Adım Sırası Sınıflandırma Raporu:\")\n",
        "print(classification_report(y_valid_step, step_predictions))\n",
        "\n",
        "print(\"Koşul Durumu Sınıflandırma Raporu:\")\n",
        "print(classification_report(y_valid_condition, condition_predictions))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMLUUWhA+lTAGuqs7ec1Jag"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}